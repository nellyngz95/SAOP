{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad26070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia.standard as ess\n",
    "import essentia\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import soundfile as sf \n",
    "import soundata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56489985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Labels\n",
      "  Label\n",
      "0     2\n",
      "1     3\n",
      "2     4\n",
      "3     5\n",
      "4     1\n",
      "5     0\n"
     ]
    }
   ],
   "source": [
    "def extract_class_ids(path):\n",
    "    print(\"Extracting Labels\")\n",
    "    \n",
    "    # Initialize a dictionary to hold the class IDs for each file\n",
    "    label_data = {\n",
    "        'Label': []  # List to store each class ID found\n",
    "    }\n",
    "\n",
    "    # Traverse the directory to collect class IDs based on the filename\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                try:\n",
    "                    # Extract class ID by splitting based on the underscore and dot\n",
    "                    label = filename.split('-')[1].split('.')[0]\n",
    "                    label_data['Label'].append(label)\n",
    "                except IndexError:\n",
    "                    print(f\"Filename format issue with: {filename}\")\n",
    "                    label_data['Label'].append(None)  # Assign None if class extraction fails\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    return pd.DataFrame(label_data)\n",
    "\n",
    "# Example usage\n",
    "path = '/Users/nellygarcia/Desktop/SubjectiveTest/Applause/Change'  # Replace with the actual dataset path\n",
    "df = extract_class_ids(path)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "523a9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(path):\n",
    "    print (\"Label\")\n",
    "    # Initialize a dictionary to hold the labels for each file\n",
    "    label_data = {\n",
    "        'Label': []  # List to store each label found\n",
    "    }\n",
    "\n",
    "    # Traverse the directory to collect labels based on the filename\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                try:\n",
    "                    # Assuming labels are the second part of the filename (e.g., file-label.wav)\n",
    "                    label = filename.split('-')[1].split('.')[0]\n",
    "                    label_data['Label'].append(label)\n",
    "                except IndexError:\n",
    "                    print(f\"Filename format issue with: {filename}\")\n",
    "                    label_data['Label'].append(None)  # Assign None if label extraction fails\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    return pd.DataFrame(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166e349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_features(path):\n",
    "    \n",
    "    print(\"Spectral\")\n",
    "    data = {\n",
    "        'Frequency1': [], 'Amplitude1': [],\n",
    "        'Frequency2': [], 'Amplitude2': [],\n",
    "        'Frequency3': [], 'Amplitude3': [],\n",
    "        'Frequency4': [], 'Amplitude4': [],\n",
    "        'Frequency5': [], 'Amplitude5': []\n",
    "    }\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                try:\n",
    "                    loader = ess.MonoLoader(filename=file_path, sampleRate=44100)\n",
    "                    audio = loader()\n",
    "\n",
    "                    frameSize = 2048\n",
    "                    hopSize = 1024\n",
    "                    windowing = ess.Windowing(type='blackmanharris62', zeroPadding=2048)\n",
    "                    spectrum = ess.Spectrum(size=frameSize)\n",
    "                    spectral_peaks = ess.SpectralPeaks(maxPeaks=5)\n",
    "\n",
    "                    all_frequencies = []\n",
    "                    all_amplitudes = []\n",
    "\n",
    "                    for frame in ess.FrameGenerator(audio, frameSize=frameSize, hopSize=hopSize):\n",
    "                        frame_spectrum = spectrum(windowing(frame))\n",
    "                        peaks_frame = spectral_peaks(frame_spectrum)\n",
    "                        all_frequencies.extend(peaks_frame[0])\n",
    "                        all_amplitudes.extend(peaks_frame[1])\n",
    "\n",
    "                    # Get the top 5 spectral peaks\n",
    "                    peaks = sorted(zip(all_frequencies, all_amplitudes), key=lambda x: x[1], reverse=True)[:5]\n",
    "                    frequencies, amplitudes = zip(*peaks) if peaks else ([], [])\n",
    "\n",
    "                    # Pad with zeros if fewer than 5 peaks\n",
    "                    frequencies = list(frequencies) + [0] * (5 - len(frequencies))\n",
    "                    amplitudes = list(amplitudes) + [0] * (5 - len(amplitudes))\n",
    "\n",
    "                    # Append values to the data dictionary\n",
    "                    for i in range(5):\n",
    "                        data[f'Frequency{i+1}'].append(frequencies[i])\n",
    "                        data[f'Amplitude{i+1}'].append(amplitudes[i])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "                    # Append NaN values if an error occurs\n",
    "                    for i in range(5):\n",
    "                        data[f'Frequency{i+1}'].append(float('nan'))\n",
    "                        data[f'Amplitude{i+1}'].append(float('nan'))\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ba78fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tempfeatures(path):\n",
    "    print(\"Temp\")\n",
    "    # Initialize lists to collect individual temporal features for all files\n",
    "    loudness_data = []\n",
    "    rms_data = []\n",
    "    spectral_flux_data = []\n",
    "    centroid_data = []\n",
    "    high_freq_content_data = []\n",
    "    zcr_data = []\n",
    "    energy_data = []\n",
    "    pitch_salience_data = []\n",
    "    effective_duration_data = []\n",
    "    decrease_data = []\n",
    "    intensity_data = []\n",
    "    dyn_complexity_data = []\n",
    "    ldb_data = []\n",
    "    cm1_data = []\n",
    "    cm2_data = []\n",
    "    cm3_data = []\n",
    "    cm4_data = []\n",
    "    cm5_data = []\n",
    "\n",
    "    # Traverse the directory to process each .wav file\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                # Initialize default feature values for the current file as NaN\n",
    "                features = {\n",
    "                    'Loudness': np.nan,\n",
    "                    'RMS': np.nan,\n",
    "                    'SpectralFlux': np.nan,\n",
    "                    'Centroid': np.nan,\n",
    "                    'HighFrequencyContent': np.nan,\n",
    "                    'ZCR': np.nan,\n",
    "                    'Energy': np.nan,\n",
    "                    'PitchSalience': np.nan,\n",
    "                    'EffectiveDuration': np.nan,\n",
    "                    'Decrease': np.nan,\n",
    "                    'Intensity': np.nan,\n",
    "                    'DynComplexity': np.nan,\n",
    "                    'LDB': np.nan,\n",
    "                    'CM1': np.nan,\n",
    "                    'CM2': np.nan,\n",
    "                    'CM3': np.nan,\n",
    "                    'CM4': np.nan,\n",
    "                    'CM5': np.nan\n",
    "                }\n",
    "\n",
    "              \n",
    "                    # Load the audio file\n",
    "                loader = ess.MonoLoader(filename=file_path, sampleRate=44100)\n",
    "                audio = loader()\n",
    "                features['Loudness'] = ess.Loudness()(audio)\n",
    "                features['RMS'] = ess.RMS()(audio)\n",
    "                features['SpectralFlux'] = ess.Flux()(audio)\n",
    "                features['Centroid'] = ess.Centroid()(audio)\n",
    "                features['HighFrequencyContent'] = ess.HFC()(audio)\n",
    "                features['ZCR'] = ess.ZeroCrossingRate()(audio)\n",
    "                features['Energy'] = ess.Energy()(audio)\n",
    "                features['PitchSalience'] = ess.PitchSalience()(audio)\n",
    "                features['EffectiveDuration'] = ess.EffectiveDuration()(audio)\n",
    "                features['Decrease'] = ess.Decrease()(audio)\n",
    "                features['Intensity'] = ess.Intensity()(audio)\n",
    "\n",
    "                    # Dynamic complexity and central moments (handling tuple unpacking)\n",
    "                dyncomp = ess.DynamicComplexity()(audio)\n",
    "                features['DynComplexity'], features['LDB'] = dyncomp  # Unpacking if it returns a tuple\n",
    "                CM = ess.CentralMoments()(audio)\n",
    "                features['CM1'], features['CM2'], features['CM3'], features['CM4'], features['CM5'] = CM\n",
    "\n",
    "            \n",
    "\n",
    "                # Append each feature individually to the respective lists\n",
    "                loudness_data.append(features['Loudness'])\n",
    "                rms_data.append(features['RMS'])\n",
    "                spectral_flux_data.append(features['SpectralFlux'])\n",
    "                centroid_data.append(features['Centroid'])\n",
    "                high_freq_content_data.append(features['HighFrequencyContent'])\n",
    "                zcr_data.append(features['ZCR'])\n",
    "                energy_data.append(features['Energy'])\n",
    "                pitch_salience_data.append(features['PitchSalience'])\n",
    "                effective_duration_data.append(features['EffectiveDuration'])\n",
    "                decrease_data.append(features['Decrease'])\n",
    "                intensity_data.append(features['Intensity'])\n",
    "                dyn_complexity_data.append(features['DynComplexity'])\n",
    "                ldb_data.append(features['LDB'])\n",
    "                cm1_data.append(features['CM1'])\n",
    "                cm2_data.append(features['CM2'])\n",
    "                cm3_data.append(features['CM3'])\n",
    "                cm4_data.append(features['CM4'])\n",
    "                cm5_data.append(features['CM5'])\n",
    "\n",
    "    # Create a DataFrame from all the lists of features\n",
    "    temp_features_df = pd.DataFrame({\n",
    "        'Loudness': loudness_data,\n",
    "        'RMS': rms_data,\n",
    "        'SpectralFlux': spectral_flux_data,\n",
    "        'Centroid': centroid_data,\n",
    "        'HighFrequencyContent': high_freq_content_data,\n",
    "        'ZCR': zcr_data,\n",
    "        'Energy': energy_data,\n",
    "        'PitchSalience': pitch_salience_data,\n",
    "        'EffectiveDuration': effective_duration_data,\n",
    "        'Decrease': decrease_data,\n",
    "        'Intensity': intensity_data,\n",
    "        'DynComplexity': dyn_complexity_data,\n",
    "        'LDB': ldb_data,\n",
    "        'CM1': cm1_data,\n",
    "        'CM2': cm2_data,\n",
    "        'CM3': cm3_data,\n",
    "        'CM4': cm4_data,\n",
    "        'CM5': cm5_data\n",
    "    })\n",
    "\n",
    "    return temp_features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb313403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_features(path):\n",
    "    print(\"Stats\")\n",
    "    # Initialize lists to collect statistical features for all files\n",
    "    mean_data = []\n",
    "    median_data = []\n",
    "    variance_data = []\n",
    "    instant_power_data = []\n",
    "    crest_data = []\n",
    "    max_to_total_data = []\n",
    "    min_to_total_data = []\n",
    "    tc_to_total_data = []\n",
    "    flatness_sfx_data = []\n",
    "    log_attack_time_data = []\n",
    "    attack_start_data = []\n",
    "    attack_stop_data = []\n",
    "    spread_data = []\n",
    "    skewness_data = []\n",
    "    kurtosis_data = []\n",
    "\n",
    "    # Traverse directory to process each .wav file\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                # Initialize default feature values for the current file\n",
    "                stats = {\n",
    "                    'Mean': 0,\n",
    "                    'Median': 0,\n",
    "                    'Variance': 0,\n",
    "                    'InstantPower': 0,\n",
    "                    'Crest': 0,\n",
    "                    'MaxToTotal': 0,\n",
    "                    'MinToTotal': 0,\n",
    "                    'TCToTotal': 0,\n",
    "                    'FlatnessSFX': 0,\n",
    "                    'LogAttackTime': 0,\n",
    "                    'AttackStart': 0,\n",
    "                    'AttackStop': 0,\n",
    "                    'Spread': 0,\n",
    "                    'Skewness': 0,\n",
    "                    'Kurtosis': 0\n",
    "                }\n",
    "\n",
    "                # Load audio\n",
    "                loader = ess.MonoLoader(filename=file_path, sampleRate=44100)\n",
    "                audio = loader()\n",
    "\n",
    "                # Extract features\n",
    "                stats['Mean'] = ess.Mean()(audio)\n",
    "                stats['Median'] = ess.Median()(audio)\n",
    "                stats['Variance'] = ess.Variance()(audio)\n",
    "                stats['InstantPower'] = ess.InstantPower()(audio)\n",
    "                stats['Crest'] = ess.Crest()(abs(audio))\n",
    "                \n",
    "                # Distribution and temporal features\n",
    "                CM = ess.CentralMoments()(audio)\n",
    "                DS = ess.DistributionShape()(CM)\n",
    "                stats['Spread'], stats['Skewness'], stats['Kurtosis'] = DS\n",
    "\n",
    "                envelope = ess.Envelope()(audio)\n",
    "                if np.all(envelope == 0) or np.sum(envelope) == 0:\n",
    "                    stats['TCToTotal'] = np.nan\n",
    "                    stats['FlatnessSFX'] = np.nan\n",
    "                    stats['MaxToTotal'] = np.nan\n",
    "                    stats['MinToTotal'] = np.nan\n",
    "                else:\n",
    "                    stats['TCToTotal'] = ess.TCToTotal()(envelope)\n",
    "                    stats['TCToTotal'] = np.nan if stats['TCToTotal'] == 0 else stats['TCToTotal']\n",
    "\n",
    "                    stats['FlatnessSFX'] = ess.FlatnessSFX()(envelope)\n",
    "                    stats['FlatnessSFX'] = np.nan if stats['FlatnessSFX'] == 0 else stats['FlatnessSFX']\n",
    "\n",
    "                    stats['MaxToTotal'] = ess.MaxToTotal()(envelope)\n",
    "                    stats['MaxToTotal'] = np.nan if stats['MaxToTotal'] == 0 else stats['MaxToTotal']\n",
    "\n",
    "                    stats['MinToTotal'] = ess.MinToTotal()(envelope)\n",
    "                    stats['MinToTotal'] = np.nan if stats['MinToTotal'] == 0 else stats['MinToTotal']\n",
    "\n",
    "                # Attack features\n",
    "                ltt, lst, lstop = ess.LogAttackTime()(envelope)\n",
    "                stats['LogAttackTime'] = ltt\n",
    "                stats['AttackStart'] = lst\n",
    "                stats['AttackStop'] = lstop\n",
    "\n",
    "                # Append each feature individually to the respective lists\n",
    "                mean_data.append(stats['Mean'])\n",
    "                median_data.append(stats['Median'])\n",
    "                variance_data.append(stats['Variance'])\n",
    "                instant_power_data.append(stats['InstantPower'])\n",
    "                crest_data.append(stats['Crest'])\n",
    "                max_to_total_data.append(stats['MaxToTotal'])\n",
    "                min_to_total_data.append(stats['MinToTotal'])\n",
    "                tc_to_total_data.append(stats['TCToTotal'])\n",
    "                flatness_sfx_data.append(stats['FlatnessSFX'])\n",
    "                log_attack_time_data.append(stats['LogAttackTime'])\n",
    "                attack_start_data.append(stats['AttackStart'])\n",
    "                attack_stop_data.append(stats['AttackStop'])\n",
    "                spread_data.append(stats['Spread'])\n",
    "                skewness_data.append(stats['Skewness'])\n",
    "                kurtosis_data.append(stats['Kurtosis'])\n",
    "\n",
    "    # Create a DataFrame from all the lists of features\n",
    "    stats_features_df = pd.DataFrame({\n",
    "        'Mean': mean_data,\n",
    "        'Median': median_data,\n",
    "        'Variance': variance_data,\n",
    "        'InstantPower': instant_power_data,\n",
    "        'Crest': crest_data,\n",
    "        'MaxToTotal': max_to_total_data,\n",
    "        'MinToTotal': min_to_total_data,\n",
    "        'TCToTotal': tc_to_total_data,\n",
    "        'FlatnessSFX': flatness_sfx_data,\n",
    "        'LogAttackTime': log_attack_time_data,\n",
    "        'AttackStart': attack_start_data,\n",
    "        'AttackStop': attack_stop_data,\n",
    "        'Spread': spread_data,\n",
    "        'Skewness': skewness_data,\n",
    "        'Kurtosis': kurtosis_data\n",
    "    })\n",
    "\n",
    "    return stats_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79e4023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timbre_features(path):\n",
    "    print(\"Timbre\")\n",
    "    # Initialize lists to collect timbre features for all files\n",
    "    pitch_salience_data = []\n",
    "    pitch_values_data = []\n",
    "    pitch_confidence_data = []\n",
    "\n",
    "    # Traverse directory to process each .wav file\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                # Load audio\n",
    "                loader = ess.MonoLoader(filename=file_path, sampleRate=44100)\n",
    "                audio = loader()\n",
    "\n",
    "                # Initialize pitch extractor and values\n",
    "                try:\n",
    "                    # Initialize pitch extractor\n",
    "                    pitch_extractor = ess.PredominantPitchMelodia(frameSize=2048, hopSize=128)\n",
    "                    \n",
    "                    # Extract pitch values and pitch confidence\n",
    "                    pitch_values, pitch_confidence = pitch_extractor(audio)\n",
    "                    \n",
    "                    # Calculate PitchSalience\n",
    "                    pitch_salience = ess.PitchSalience()(audio)\n",
    "\n",
    "                    # Compute median of pitch_values and pitch_confidence\n",
    "                    pitch_values_median = np.median(pitch_values) if len(pitch_values) > 0 else 0\n",
    "                    pitch_confidence_median = np.median(pitch_confidence) if len(pitch_confidence) > 0 else 0\n",
    "\n",
    "                    # Append the extracted features to the respective lists\n",
    "                    pitch_salience_data.append(pitch_salience)\n",
    "                    pitch_values_data.append(pitch_values_median)\n",
    "                    pitch_confidence_data.append(pitch_confidence_median)\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Append NaN values if an error occurs\n",
    "                    pitch_salience_data.append(np.nan)\n",
    "                    pitch_values_data.append(np.nan)\n",
    "                    pitch_confidence_data.append(np.nan)\n",
    "\n",
    "    # Create a DataFrame from the lists of timbre features\n",
    "    timbre_features_df = pd.DataFrame({\n",
    "        'PitchSalience': pitch_salience_data,  \n",
    "        'PitchValues': pitch_values_data,\n",
    "        'PitchConfidence': pitch_confidence_data\n",
    "    })\n",
    "\n",
    "    return timbre_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dff1495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcs(path):\n",
    "    print(\"MFCC\")\n",
    "    # Initialize lists to collect MFCC features for all files\n",
    "    mfcc_features_data = [[] for _ in range(13)]  # List for each of the 13 MFCC coefficients\n",
    "\n",
    "    # Traverse directory to process each .wav file\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                # Load audio\n",
    "                loader = ess.MonoLoader(filename=file_path, sampleRate=44100)\n",
    "                audio = loader()\n",
    "\n",
    "                # Parameters for frame-based processing\n",
    "                frame_size = 2048\n",
    "                hop_size = 512\n",
    "                windowing = ess.Windowing(type='hann')\n",
    "                spectrum = ess.Spectrum()\n",
    "                mfcc_extractor = ess.MFCC()\n",
    "\n",
    "                mfcc_list = []\n",
    "\n",
    "                # Process audio frame-by-frame\n",
    "                for frame in ess.FrameGenerator(audio, frameSize=frame_size, hopSize=hop_size):\n",
    "                    windowed_frame = windowing(frame)\n",
    "                    spectrum_frame = spectrum(windowed_frame)\n",
    "                    mfcc_bands, mfcc_coefficients = mfcc_extractor(spectrum_frame)\n",
    "                    mfcc_list.append(mfcc_coefficients)\n",
    "\n",
    "                # Calculate mean MFCCs over all frames\n",
    "                mfcc_means = [np.mean(coef) for coef in zip(*mfcc_list)]\n",
    "\n",
    "                # Append each MFCC feature to its corresponding list\n",
    "                for i, mfcc_mean in enumerate(mfcc_means):\n",
    "                    mfcc_features_data[i].append(mfcc_mean)\n",
    "\n",
    "    # Create a DataFrame from the lists of MFCC features\n",
    "    mfcc_features_df = pd.DataFrame({\n",
    "        f'MFCC_{i+1}': mfcc_features_data[i] for i in range(13)\n",
    "    })\n",
    "\n",
    "    return mfcc_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b98db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(path):\n",
    "    print (\"STFT\")\n",
    "    # Initialize lists to collect STFT features for all files\n",
    "    stft_features_data = [[], [], []]  # Lists for SpecComplexity, RollOff, and StrongPeak\n",
    "\n",
    "    # Traverse directory to process each .wav file\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                # Load audio\n",
    "                loader = ess.MonoLoader(filename=file_path, sampleRate=44100)\n",
    "                audio = loader()\n",
    "\n",
    "                # Calculate spectrum and spectral features\n",
    "                spectrum = ess.Spectrum()(audio)\n",
    "                spectrum_vector = np.abs(spectrum)\n",
    "\n",
    "                # Extract spectral features\n",
    "                spec_complexity = ess.SpectralComplexity()(spectrum_vector)\n",
    "                rolloff = ess.RollOff()(spectrum_vector)\n",
    "                strong_peak = ess.StrongPeak()(spectrum_vector)\n",
    "\n",
    "                # Append extracted features to their respective lists\n",
    "                stft_features_data[0].append(spec_complexity)  # SpecComplexity\n",
    "                stft_features_data[1].append(rolloff)  # RollOff\n",
    "                stft_features_data[2].append(strong_peak)  # StrongPeak\n",
    "\n",
    "    # Create a DataFrame from the lists of STFT features\n",
    "    stft_features_df = pd.DataFrame({\n",
    "        'SpecComplexity': stft_features_data[0],\n",
    "        'RollOff': stft_features_data[1],\n",
    "        'StrongPeak': stft_features_data[2]\n",
    "    })\n",
    "\n",
    "    return stft_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dca6e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(path):\n",
    "    print(\"All Features\")\n",
    "    # Label extraction (assuming `extract_labels` is defined)\n",
    "    labels =extract_class_ids(path)\n",
    "    #extract_labels(path)\n",
    "    \n",
    "    # Spectral features (assuming `extract_spectral_features` is defined)\n",
    "    \n",
    "    spectral_features= extract_spectral_features(path)\n",
    "    temp_features=extract_tempfeatures(path)\n",
    "    stats_features=stat_features(path)\n",
    "    timbres_features=timbre_features(path)\n",
    "    mfc_coef=mfcs(path)\n",
    "    stfts=stft(path)\n",
    "\n",
    "    #print(f\"Stats Features Shape: {stats_features.shape}\")\n",
    "   \n",
    "    \n",
    "    # Combine all features into a final DataFrame\n",
    "    final_df = pd.concat([spectral_features,temp_features,stats_features,timbres_features,mfc_coef,stfts], axis=1)\n",
    "    \n",
    "    # Add labels column\n",
    "    final_df['Label'] = labels\n",
    "    print(\"Processing files\")\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eded53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Labels\n",
      "All Features\n",
      "Extracting Labels\n",
      "Spectral\n",
      "Temp\n",
      "Stats\n",
      "Timbre\n",
      "MFCC\n",
      "STFT\n",
      "Processing files\n",
      "   Frequency1  Amplitude1  Frequency2  Amplitude2  Frequency3  Amplitude3  \\\n",
      "0  373.461060    0.175692  614.352905    0.130413  597.080872    0.105932   \n",
      "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "2  476.796326    0.218564  908.257812    0.202868  843.625671    0.176683   \n",
      "3  406.471130    0.239366  440.455597    0.094429  407.310608    0.017755   \n",
      "4  640.595398    0.048330  709.951355    0.023669  748.738342    0.022345   \n",
      "5  702.231934    0.178786  780.624939    0.139381  694.673279    0.108246   \n",
      "\n",
      "    Frequency4  Amplitude4   Frequency5  Amplitude5  ...     MFCC_8    MFCC_9  \\\n",
      "0   854.970093    0.053560   350.300446    0.044825  ...   0.735194 -1.142178   \n",
      "1     0.000000    0.000000     0.000000    0.000000  ...  -0.000069 -0.000050   \n",
      "2  1024.207275    0.111187  1192.126465    0.092568  ...   3.208831 -1.096757   \n",
      "3   708.503723    0.009782   496.991791    0.006041  ...  -1.136223 -0.111553   \n",
      "4  1104.199951    0.020673   991.881531    0.017718  ...   1.885932  0.133148   \n",
      "5   776.287964    0.090185   698.957825    0.076288  ...  11.112453  4.615247   \n",
      "\n",
      "    MFCC_10   MFCC_11    MFCC_12   MFCC_13  SpecComplexity      RollOff  \\\n",
      "0 -1.953860 -1.648903  -0.382858  0.482660           100.0   714.599976   \n",
      "1 -0.000019 -0.000023  -0.000019 -0.000042             0.0     0.000000   \n",
      "2 -2.535931 -1.863336  -1.850159 -0.567537           100.0  1223.800049   \n",
      "3  0.288840  0.386240   0.091475 -0.274096           100.0   483.600006   \n",
      "4 -0.905832 -1.244202  -0.366243  0.593126           100.0  1028.800049   \n",
      "5 -2.568875 -1.211322 -10.339445 -2.733110           100.0  1020.400024   \n",
      "\n",
      "     StrongPeak  Label  \n",
      "0  1.616263e+05      3  \n",
      "1  0.000000e+00      5  \n",
      "2  1.116280e+06      1  \n",
      "3  1.931117e+03      2  \n",
      "4  5.907248e+03      4  \n",
      "5  1.987095e+06      0  \n",
      "\n",
      "[6 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/nellygarcia/Desktop/SubjectiveTest/Bubbles/Changes\"\n",
    "labels = extract_class_ids(path)\n",
    "final_df = extract_all_features(path)\n",
    "print (final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7776ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /Users/nellygarcia/Desktop/SubjectiveTest/Bubbles/change.csv\n"
     ]
    }
   ],
   "source": [
    "csv_output_path = '/Users/nellygarcia/Desktop/SubjectiveTest/Bubbles/change.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "final_df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05d7b507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ File not found: /Users/nellygarcia/Downloads/Test/5-220026-A-21.wav\n",
      "❌ File not found: /Users/nellygarcia/Downloads/Test/4-207116-A-23.wav\n",
      "❌ File not found: /Users/nellygarcia/Downloads/Test/5-219379-C-11.wav\n",
      "❌ File not found: /Users/nellygarcia/Downloads/Test/5-198321-A-10.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# List of corrupted files\n",
    "corrupted_files = [\n",
    "    \"5-220026-A-21.wav\",\n",
    "    \"4-207116-A-23.wav\",\n",
    "    \"5-219379-C-11.wav\",\n",
    "    \"5-198321-A-10.wav\"\n",
    "]\n",
    "\n",
    "# Path to dataset folder\n",
    "dataset_path = \"/Users/nellygarcia/Downloads/Test\"\n",
    "\n",
    "def fix_wav_files(files, dataset_path):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(dataset_path, filename)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"❌ File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Check file size\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            print(f\"⚠️ Empty file detected: {file_path} (Re-download required!)\")\n",
    "            continue\n",
    "\n",
    "        # Create output path\n",
    "        output_path = os.path.join(dataset_path, \"fixed_\" + filename)\n",
    "\n",
    "        print(f\"🔧 Fixing: {filename} ...\")\n",
    "\n",
    "        # Use ffmpeg to convert the WAV file to a valid format\n",
    "        command = [\n",
    "            \"ffmpeg\", \"-i\", file_path, \"-acodec\", \"pcm_s16le\", \"-ar\", \"44100\", output_path, \"-y\"\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "            print(f\"✅ Fixed: {filename} → {output_path}\")\n",
    "\n",
    "            # Replace the corrupted file with the fixed one\n",
    "            os.replace(output_path, file_path)\n",
    "            print(f\"🔄 Replaced original file with the fixed version.\")\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ Failed to fix {filename}: {e}\")\n",
    "\n",
    "# Run the function\n",
    "fix_wav_files(corrupted_files, dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976d630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
